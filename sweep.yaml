# first we specify what we're sweeping
# we specify a program to run
program: run_all.py
# we optionally specify how to run it, including setting default arguments
command:  
    - ${env}
    - ${interpreter}
    - ${program}
    - "--wandb"
    - "--limit_val_batches"
    - "5"
    - "--limit_train_batches"
    - "10"
    - "--log_every_n_steps"
    - "2"
    - "--max_epochs"
    - "5"
    - ${args}  # these arguments come from the sweep parameters below

# and we specify which parameters to sweep over, what we're optimizing, and how we want to optimize it
method: random  # generally, random searches perform well, can also be "grid" or "bayes"
metric:
    name: test_loss
    goal: minimize
parameters:  
    # litmodel hyperparameters
    lr:
        values: [0.001, 0.01]
    # ViT hyperparameters
    #patch_len:
    #    values: [1, 2, 3]
    dropout:
        values: [0.1, 0.2, 0.3]
    # we can also fix some values, just like we set default arguments
    #gpus:
    #    value: 1
    model_class:
        value: vit.simpleVIT
    data_class:
        value: xarray_module.XarrayDataModule
    ft_schedule:
        value: hyperiap/litmodels/LitClassifier_ft_schedule_final.yaml